import argparse
def argument():
    parser = argparse.ArgumentParser(description = '''
    Prepares Monthly Validation Report,
    a NetCDF file whose name is like this
    product_quality_stats_MEDSEA_ANALYSISFORECAST_BGC_006_014_20210501_20210531.nc
    to be sent to the PQ dashboard
    for satellite and float.
    Statistics are operationally generated by:
    - SatValidation.py
    - biofloats_ms_MVR.py
    ''',
    formatter_class=argparse.RawTextHelpFormatter
    )

    parser.add_argument(   '--outdir', '-o',
                            type = str,
                            required =False,
                            default = "./",
                            help = ''' Output dir'''
                            )

    parser.add_argument(   '--inputsat', '-i',
                            type = str,
                            required = True,
                            help = '''Directory where outputs of SatValidation.py (f1,f2,f3,pers files) are stored
Operationally is inpdir/analysis/VALIDATION/SAT''')

    parser.add_argument(   '--inputfloat', '-t',
                            type = str,
                            required = True,
                            help = '''Directory where outputs of biofloats_ms_MVR.py are stored
Operationally is inpdir/analysis/VALIDATION/FLOAT/WEEKLY_CLIM''')

    parser.add_argument(   '--month','-m',
                                type = str,
                                required = True,
                                help = 'month in yyyymm format')
    return parser.parse_args()
args = argument()


import numpy as np
import netCDF4 as NC
import datetime
from bitsea.basins import V2 as OGS
from bitsea.commons.utils import addsep
from bitsea.commons.Timelist import TimeList
from bitsea.commons.time_interval import TimeInterval
from bitsea.commons import genUserDateList as DL
from bitsea.commons import timerequestors as requestors
import calendar
import sys

INDIRSAT = addsep(args.inputsat)
INDIRFLOAT = addsep(args.inputfloat)
OUTDIR = addsep(args.outdir)

nYEAR=int(args.month[0:4])
nMONTH=int(args.month[4:6])
productname = "MEDSEA_ANALYSISFORECAST_BGC_006_014"
month_lastday = calendar.monthrange(nYEAR,nMONTH)[1]
Ndates = month_lastday

STARTTIME = args.month + '01'
END__TIME = args.month + '%02d' %month_lastday

AllDates = DL.getTimeList(STARTTIME + '-00:00:00',END__TIME + '-23:59:59',days=1)


TI = TimeInterval(STARTTIME,END__TIME)
Month = STARTTIME[4:6]

TLfloat = TimeList.fromfilenames(TI,INDIRFLOAT,"BioFloat_Weekly*nc", \
                    prefix="BioFloat_Weekly_validation_", \
                    dateformat='%Y%m%d')

#### Sat
TLsat = {}

LISTforecast = ['f%d' %ii for ii in range(1,4)]
LISTforecast.append('pers')
Nforecast = len(LISTforecast)

leadtimes = np.zeros((Nforecast,),int)
for iforecast,ff in enumerate(LISTforecast):
    if ff[0]=='f':
        nday = int(ff[1])
        leadtimes[iforecast] = 12+24*iforecast
    if 'p' in ff:
        leadtimes[iforecast] = -12


for ff in LISTforecast:
    TLsat[ff] = TimeList.fromfilenames(TI,INDIRSAT,"Validation_" + ff + "*", \
                        prefix="Validation_" + ff + "_YYYYMMDD_on_daily_Sat.", \
                        dateformat='%Y%m%d')

#### end Sat

METRICS_NAMES = [
    'number of data values',
    'mean of product',
    'mean of reference',
    'mean squared error',
    'variance of product',
    'variance of reference',
    'anomaly correlation',
    'correlation',
    ]



##### SATLLITE ####

LISTmetrics_SAT = [
    'number',
    'SAT___MEAN_LOG',
    'MODEL_MEAN_LOG',
    'SAT___VARIANCE_LOG',
    'MODEL_VARIANCE_LOG',
    'BGC_CLASS4_CHL_RMS_SURF_BASIN_LOG',
    'BGC_CLASS4_CHL_BIAS_SURF_BASIN_LOG',
    'BGC_CLASS4_CHL_CORR_SURF_BASIN_LOG',
    'ANOMALY_CORRELATION_LOG',
    'SAT___MEAN',
    'MODEL_MEAN',
    'SAT___VARIANCE',
    'MODEL_VARIANCE',
    'BGC_CLASS4_CHL_RMS_SURF_BASIN',
    'BGC_CLASS4_CHL_BIAS_SURF_BASIN',
    'BGC_CLASS4_CHL_CORR_SURF_BASIN',
    'ANOMALY_CORRELATION',
]

maxlenght_names = '%d' %(max(len(ww) for ww in LISTmetrics_SAT))

DICTmetricnames = {}
for tt in ['LOG','NOLOG']:
    dtype = [(mname,'S'+maxlenght_names) for mname in METRICS_NAMES]
    DICTmetricnames[tt] = np.zeros(1,dtype) 
    if tt=='LOG':
        stringlog = '_' + tt
    else:
        stringlog = ''
    
    DICTmetricnames[tt]['number of data values'] = 'number'
    DICTmetricnames[tt]['mean of product']   = 'MODEL_MEAN' + stringlog
    DICTmetricnames[tt]['mean of reference'] = 'SAT___MEAN' + stringlog
    DICTmetricnames[tt]['mean squared error'] = 'BGC_CLASS4_CHL_RMS_SURF_BASIN' + stringlog
    DICTmetricnames[tt]['variance of product']   = 'MODEL_VARIANCE' + stringlog
    DICTmetricnames[tt]['variance of reference'] = 'SAT___VARIANCE' + stringlog
    DICTmetricnames[tt]['anomaly correlation'] = 'ANOMALY_CORRELATION' + stringlog
    DICTmetricnames[tt]['correlation'] = 'BGC_CLASS4_CHL_CORR_SURF_BASIN' + stringlog


file1 = TLsat['f1'].filelist[0]
M1 = NC.Dataset(file1,"r")
M_AREAS = M1.sublist.split(',')[:-1]
AREA_NAMES = []
indexAREAS = {}
for sub in OGS.P.basin_list:
    if 'atl' in sub.name: continue
    AREA_NAMES.append(sub.extended_name)
    indexAREAS[sub.extended_name] = M_AREAS.index(sub.name)

ALLstring = AREA_NAMES[:]
ALLstring.extend(METRICS_NAMES)
max_strlenght = max(len(aa) for aa in ALLstring)


Nmetrics = len(METRICS_NAMES)
Nsub = len(AREA_NAMES)

MetricsSAT = {}
for tt in ['LOG','NOLOG']:
    MetricsSAT[tt] = np.zeros((Ndates,Nforecast,Nmetrics,Nsub))
    MetricsSAT[tt][:] = np.nan
    TIMELIST = np.zeros((Ndates,),np.float32)


    for idate,datef in enumerate(AllDates):
        req = requestors.Daily_req(datef.year,datef.month,datef.day)
        TIMELIST[idate] = datef.toordinal() - datetime.datetime(1950,1,1).toordinal()
        for iforecast,ff in enumerate(LISTforecast):
            ii = TLsat[ff].select_one(req)
            if ii==None: continue
            filef = TLsat[ff].filelist[ii]
        
            M = NC.Dataset(filef,"r")
            for mm,metric in enumerate(METRICS_NAMES):
                for isub,subname in enumerate(AREA_NAMES):
                    varname = DICTmetricnames[tt][0][metric].decode()
                    MetricsSAT[tt][idate,iforecast,mm,isub] = M.variables[varname][indexAREAS[subname],1].data.copy()
        
    masknan = np.isnan(MetricsSAT[tt])
    MetricsSAT[tt][masknan] = 1.e+20

#### FLOAT #############


TLfloat = TimeList.fromfilenames(TI,INDIRFLOAT,"BioFloat_Weekly*nc", \
                    prefix="BioFloat_Weekly_validation_", \
                    dateformat='%Y%m%d')

LISTmetrics_FLOAT = [
    'nobs',
    'modelmean',
    'refmean',
    'mse',
    'modelvar',
    'refvar',
    'bias',
    'BGC_CLASS4_CHL_CORR_SURF_BASIN_LOG',
    'anomaly_corr',
    'corr',
]

maxlenght_mames = '%d' %(max(len(ww) for ww in LISTmetrics_FLOAT))

dtype = [(mname,'S'+maxlenght_mames) for mname in METRICS_NAMES]
DICTmetricnames = np.zeros(1,dtype)

DICTmetricnames['number of data values'] = 'nobs'
DICTmetricnames['mean of product']   = 'modelmean'
DICTmetricnames['mean of reference'] = 'refmean'
DICTmetricnames['mean squared error'] = 'mse'
DICTmetricnames['variance of product']   = 'modelvar'
DICTmetricnames['variance of reference'] = 'refvar'
DICTmetricnames['anomaly correlation'] = 'anomaly_corr'
DICTmetricnames['correlation']         = 'corr'


DICTsubbasins = {}
for sub in OGS.P.basin_list:
    if 'atl' in sub.name: continue
    for subaggregate in OGS.MVR.basin_list:
        if subaggregate.name in sub.name:
            DICTsubbasins[sub.name] = subaggregate.name

file1 = TLfloat.filelist[0]
M1 = NC.Dataset(file1,"r")
M_AREAS = M1.sublist.split(',')
AREA_NAMES = []
indexAREAS = {}
for sub in OGS.P.basin_list:
    if 'atl' in sub.name: continue
    AREA_NAMES.append(sub.extended_name)
    if 'aeg' in sub.name: continue
    subaggregate_name = DICTsubbasins[sub.name]
    indexAREAS[sub.extended_name] = M_AREAS.index(subaggregate_name)

ALLstring = AREA_NAMES[:]
ALLstring.extend(METRICS_NAMES)
max_strlenght = max(len(aa) for aa in ALLstring)

M_depths = M1.layerlist.split(',')
DEPTHSlist = []
for layername in M_depths:
    top,bottom_m = layername.split('-')
    #if float(top)>150 : continue
    bottom = float(bottom_m[:-1])
    DEPTHSlist.append(bottom)
Ndepths = len(DEPTHSlist)

Nmetrics = len(METRICS_NAMES)
Nsub = len(AREA_NAMES)

varlist=['P_l','N3n','O2o']
Nvar=len(varlist)

MetricsFLOAT = np.zeros((Ndates,Ndepths,Nmetrics,Nsub,Nvar))
MetricsFLOAT[:] = 1.e+20
TIMELIST = np.zeros((Ndates,),np.float32)

for idate,datef in enumerate(AllDates):
    TIMELIST[idate] = datef.toordinal() - datetime.datetime(1950,1,1).toordinal()
    ii,diffseconds = TLfloat.find(datef,returndiff=True)
    if diffseconds/24/3600>3.5: continue
    filef = TLfloat.filelist[ii]
    M = NC.Dataset(filef,"r")
    for mm,metric in enumerate(METRICS_NAMES):
        for isub,subname in enumerate(AREA_NAMES):
            if subname=='Aegean Sea': continue
            varname = DICTmetricnames[0][metric].decode()
            for ivar, VAR in enumerate (varlist):
                MetricsFLOAT[idate,:,mm,isub,ivar] = M.variables[varname][ivar,indexAREAS[subname],:Ndepths].data.copy()

masknan = np.isnan(MetricsFLOAT)
MetricsFLOAT[masknan] = 1.e+20


outfile = 'product_quality_stats_' + productname + '_' + STARTTIME + '_' + END__TIME + '.nc'
outfilepath = OUTDIR + outfile

print(outfilepath)

#import sys
#sys.exit()

S=NC.Dataset(outfilepath,"w")

S.createDimension("time"         ,None)
S.createDimension("area"        ,len(AREA_NAMES))
S.createDimension("metric"      ,len(METRICS_NAMES))
S.createDimension("depth"       ,1)
S.createDimension("layer"       ,Ndepths)
S.createDimension("forecast"    ,len(leadtimes))

subbasins_renamed = [
    "Alboran Sea",
    "South West Med western part",
    "South West Med eastern part",
    "North West Med",
    "Tyrrhenian Sea northern part",
    "Tyrrhenian Sea southern part",
    "Adriatic Sea northern part",
    "Adriatic Sea southern part",
    "Aegean Sea",
    "Ionian Sea western part",
    "Ionian Sea south-eastern part",
    "Ionian Sea north-eastern part",
    "Levantine Sea western part",
    "Levantine Sea central-northern part",
    "Levantine Sea central-southern part",
    "Levantine Sea eastern part",
    "Full domain"
]

x=np.array(ALLstring,dtype=str)

from netCDF4 import stringtochar
# writing AREA as Variable
vlen_str = S.createVLType(str, "vlen_str")
ncvar = S.createVariable("area", vlen_str, ("area",))
for i, name in enumerate(subbasins_renamed):
    ncvar[i] = name

#ncvar = S.createVariable("area", str, ("area",)) # 
#x=np.array(subbasins_renamed ,dtype=str)
#ncvar[:] = subbasins_renamed  #x[:Nsub]
setattr(S.variables['area'],"long_name"  ,"area")
setattr(S.variables['area'], "description", "Geographical areas that are included in the Region of reference")

# writing metric as Variable
ncvar = S.createVariable("metric", str, ('metric'))
ncvar[:] = x[Nsub:]
setattr(S.variables['metric'], "long_name", "List of CLASS4 metrics")

# writing forecast as Variable
ncvar = S.createVariable("forecast",'f4',('forecast',) , fill_value=-999.0)
ncvar[:] = leadtimes
setattr(S.variables['forecast'],"description","forecast lead time")
setattr(S.variables['forecast'],"units"    ,"hours")

# writing depth as Variable
ncvar = S.createVariable("depth",'f',('depth',))
ncvar[:]=np.array(0)
setattr(S.variables['depth'],"long_name"  ,"depth")
setattr(S.variables['depth'],"units"      ,"m")
setattr(S.variables['depth'], "description", "Surface level (0 m) over which statistics are calculated")


# writing layer as Variable 
ncvar = S.createVariable("layer",'f',('layer',))
ncvar[:]=np.array(DEPTHSlist)
setattr(S.variables['layer'],"long_name"  ,"layer")
setattr(S.variables['layer'],"positive"   ,"down")
setattr(S.variables['layer'],"units"      ,"m")
setattr(S.variables['layer'],"description","depth of the base of the vertical layer over which statistics are aggregated")

# writing time as Variable
ncvar = S.createVariable('time', 'f4', ('time',), fill_value=-999.0)
ncvar[:]=TIMELIST
setattr(S.variables['time'],"long_name"    ,"validity time")
setattr(S.variables['time'],"standard_name","time")
setattr(S.variables['time'],"units"        ,"days since 1950-01-01 12:00:00")
setattr(S.variables['time'],"axis"         ,"T")

# writing stats_chlorophyll-a_sat as Variable ONLY NOLOG
for tt in ['NOLOG']:  #for tt in ['LOG','NOLOG']:
    if tt=='LOG':
        stringlog = '_' + tt
    else:
        stringlog = ''
    statsname = 'stats_chlorophyll-a_sat-l3' + stringlog.lower()
    if tt=='LOG':
        parametername = 'log of Surface chlorophyll'
    else:
        parametername = "Surface Chlorophyll"
    ncvar = S.createVariable(statsname, 'f4', ('time', 'forecast', 'depth', 'metric', 'area'), fill_value=-999.0)
    ncvar[:,:,0,:,:] = MetricsSAT[tt]
    setattr(S.variables[statsname], "parameter",parametername)
    setattr(S.variables[statsname], "reference","OCEANCOLOUR_MED_BGC_L3_NRT_009_141")
    setattr(S.variables[statsname], "metric_name","CHL-SURF-D-CLASS4-SAT-PQD_EAN-XYZ-MED")
    setattr(S.variables[statsname], "units"    ,"mg Chl*m^-3") #log removed


###### saving FLOAT
# writing Chlorophyll as BGC-Argo  Variable
statsname = 'stats_chlorophyll-a_ins-pf'
parametername = "Chlorophyll"
ncvar=S.createVariable(statsname,'f4',('time', 'forecast', 'layer', 'metric', 'area'), fill_value=-999.0)

ncvar[:,:,:,:,:]   = np.nan
ncvar[:,0,:,:,:]   = MetricsFLOAT[:,:,:,:,0]
ncvar[:,:,-3:,:,:] = np.nan

setattr(S.variables[statsname], "parameter",parametername)
setattr(S.variables[statsname], "reference","BGC-Argo")
setattr(S.variables[statsname], "metric_name","CHL-X_Y-D-CLASS4-PROF-PQD_EAN-XY-MED")
setattr(S.variables[statsname], "units"    ,"mg Chl*m^-3")


# writing nitrate as BGC-Argo  Variable
statsname = 'stats_nitrate_ins-pf'
parametername = "Nitrate"
ncvar = S.createVariable(statsname, 'f4', ('time', 'forecast', 'layer', 'metric', 'area'), fill_value=-999.0)

ncvar[:,:,:,:,:] = np.nan
ncvar[:,0,:,:,:] = MetricsFLOAT[:,:,:,:,1]

setattr(S.variables[statsname], "parameter",parametername)
setattr(S.variables[statsname], "reference","BGC-Argo")
setattr(S.variables[statsname], "metric_name","NO3-X_Y-D-CLASS4-PROF-PQD_EAN-XY-MED")
setattr(S.variables[statsname], "units"    ,"mmol NO3*m^-3")

# writing Oxygen as BGC-Argo  Variable
statsname = 'stats_oxygen_ins-pf'
parametername = "Oxygen"
ncvar = S.createVariable(statsname, 'f4', ('time', 'forecast', 'layer', 'metric', 'area'), fill_value=-999.0)
ncvar[:,:,:,:,:] = np.nan
ncvar[:,0,:,:,:] = MetricsFLOAT[:,:,:,:,2]


setattr(S.variables[statsname], "parameter",parametername)
setattr(S.variables[statsname], "reference","BGC-Argo")
setattr(S.variables[statsname], "metric_name","O2-X_Y-D-CLASS4-PROF-PQD_EAN-XY-MED")
setattr(S.variables[statsname], "units"    ,"mmol O2*m^-3")


# writing metadata
setattr(S,"contact","service.med.ogs@inogs.it")
setattr(S,"product",productname)
setattr(S,"start_date",STARTTIME)
setattr(S,"end_date"  ,END__TIME)
setattr(S, "institution"  , "OGS")  
from datetime import date
today = date.today().isoformat()
setattr(S, "bulletin_date", today)
setattr(S, "frequency"    , "monthly")
#setattr(S,"filename"  ,outfile)
S.close()

